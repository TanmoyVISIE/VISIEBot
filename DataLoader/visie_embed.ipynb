{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcf30668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756358113.870017  167838 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "2823.97s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: langchain in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-community in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (0.3.23)\n",
      "Requirement already satisfied: langchain-google-genai in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (2.1.10)\n",
      "Requirement already satisfied: chromadb in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (1.0.7)\n",
      "Requirement already satisfied: pypdf in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (6.0.0)\n",
      "Collecting unstructured\n",
      "  Downloading unstructured-0.18.14-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/tanmoy/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langchain) (0.3.75)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/tanmoy/.local/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langchain-community) (3.11.18)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from langchain-google-genai) (0.6.18)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.0rc0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.39.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi==0.115.9 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (0.115.9)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (4.0.1)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (1.21.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (0.15.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Downloading lxml-6.0.1-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting nltk (from unstructured)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting beautifulsoup4 (from unstructured)\n",
      "  Downloading beautifulsoup4-4.13.5-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting emoji (from unstructured)\n",
      "  Using cached emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.14.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: backoff in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from unstructured) (2.2.1)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.42.3-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: wrapt in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from unstructured) (1.17.2)\n",
      "Requirement already satisfied: psutil in /home/tanmoy/.local/lib/python3.12/site-packages (from unstructured) (7.0.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: pyproject_hooks in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/tanmoy/.local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: sympy in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.32.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.53b1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/tanmoy/.local/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb) (0.30.2)\n",
      "Requirement already satisfied: filelock in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->unstructured)\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Collecting webencodings (from html5lib->unstructured)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting joblib (from nltk->unstructured)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from nltk->unstructured) (2024.11.6)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from unstructured-client->unstructured) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from unstructured-client->unstructured) (44.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/tanmoy/nlp books/GEN AI/.conda/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
      "Downloading unstructured-0.18.14-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading beautifulsoup4-4.13.5-py3-none-any.whl (105 kB)\n",
      "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Using cached emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading lxml-6.0.1-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading rapidfuzz-3.14.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading unstructured_client-0.42.3-py3-none-any.whl (207 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "\u001b[33m  DEPRECATION: Building 'langdetect' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'langdetect'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993284 sha256=227e064313f80699c11cbabe0e09b99fae1606ff56513046e24f69c92d8ff094\n",
      "  Stored in directory: /home/tanmoy/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built langdetect\n",
      "Installing collected packages: webencodings, soupsieve, rapidfuzz, python-magic, python-iso639, olefile, lxml, langdetect, joblib, html5lib, emoji, python-oxmsg, nltk, beautifulsoup4, unstructured-client, unstructured\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [unstructured][0m [unstructured]client]\n",
      "\u001b[1A\u001b[2KSuccessfully installed beautifulsoup4-4.13.5 emoji-2.14.1 html5lib-1.1 joblib-1.5.2 langdetect-1.0.9 lxml-6.0.1 nltk-3.9.1 olefile-0.47 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.14.0 soupsieve-2.8 unstructured-0.18.14 unstructured-client-0.42.3 webencodings-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install pandas langchain langchain-community langchain-google-genai chromadb pypdf unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26379c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from langchain_community.document_loaders import PyPDFLoader, UnstructuredHTMLLoader\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c487a06",
   "metadata": {},
   "source": [
    "For PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ce2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 PDF files to process\n"
     ]
    }
   ],
   "source": [
    "# Set your Google API key\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"******************************\"  # Replace with your actual API key\n",
    "\n",
    "# Define the path to your PDF files\n",
    "dataset_dir = \"../Data/pdf_data/\"\n",
    "pdf_files = [f for f in os.listdir(dataset_dir) if f.endswith('.pdf')]\n",
    "\n",
    "# Clean up existing chroma_db directory to avoid readonly database issues\n",
    "if os.path.exists(\"./chroma_db\"):\n",
    "    print(\"Cleaning up existing database directory...\")\n",
    "    shutil.rmtree(\"./chroma_db\")\n",
    "\n",
    "# Create fresh chroma_db directory\n",
    "os.makedirs(\"./chroma_db\", exist_ok=True)\n",
    "print(f\"Found {len(pdf_files)} PDF files to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e5545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/12: Nabila Noshin.pdf...\n",
      "  Loaded 1 pages\n",
      "  Created 2 chunks\n",
      "Created vector store with 2 chunks\n",
      "Processing 2/12: Mohammad Islam.pdf...\n",
      "  Loaded 6 pages\n",
      "  Created 11 chunks\n",
      "Created vector store with 11 chunks\n",
      "Processing 3/12: Tanmoy Shome.pdf...\n",
      "  Loaded 2 pages\n",
      "  Created 3 chunks\n",
      "Created vector store with 3 chunks\n",
      "Processing 4/12: Shanto Jouerder.pdf...\n",
      "  Loaded 4 pages\n",
      "  Created 8 chunks\n",
      "Created vector store with 8 chunks\n",
      "Processing 5/12: Abir Hasan.pdf...\n",
      "  Loaded 2 pages\n",
      "  Created 3 chunks\n",
      "Created vector store with 3 chunks\n",
      "Processing 6/12: Al Mamun Khan.pdf...\n",
      "  Loaded 6 pages\n",
      "  Created 13 chunks\n",
      "Created vector store with 13 chunks\n",
      "Processing 7/12: Abdullah al Mamun.pdf...\n",
      "  Loaded 1 pages\n",
      "  Created 1 chunks\n",
      "Created vector store with 1 chunks\n",
      "Processing 8/12: Zeshan Haider.pdf...\n",
      "  Loaded 1 pages\n",
      "  Created 1 chunks\n",
      "Created vector store with 1 chunks\n",
      "Processing 9/12: Lameya Sabrin.pdf...\n",
      "  Loaded 2 pages\n",
      "  Created 4 chunks\n",
      "Created vector store with 4 chunks\n",
      "Processing 10/12: Laboni Paul.pdf...\n",
      "  Loaded 1 pages\n",
      "  Created 2 chunks\n",
      "Created vector store with 2 chunks\n",
      "Processing 11/12: Rahul Deb Mohalder.pdf...\n",
      "  Loaded 3 pages\n",
      "  Created 5 chunks\n",
      "Created vector store with 5 chunks\n",
      "Processing 12/12: Ferdous Bin Ali.pdf...\n",
      "  Loaded 6 pages\n",
      "  Created 13 chunks\n",
      "Created vector store with 13 chunks\n",
      "All PDF files processed and embedded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Google embeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")\n",
    "\n",
    "\n",
    "# Process each PDF file\n",
    "for i, pdf_file in enumerate(pdf_files, 1):\n",
    "    try:\n",
    "        file_path = os.path.join(dataset_dir, pdf_file)\n",
    "        print(f\"Processing {i}/{len(pdf_files)}: {pdf_file}...\")\n",
    "\n",
    "        # Load the PDF file\n",
    "        loader = PyPDFLoader(file_path=file_path)\n",
    "        documents = loader.load()\n",
    "        print(f\"  Loaded {len(documents)} pages\")\n",
    "        \n",
    "        # Split the documents into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=100\n",
    "        )\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        print(f\"  Created {len(chunks)} chunks\")\n",
    "        \n",
    "        # Create a unique collection name (ChromaDB collection names must be valid)\n",
    "        collection_name = f\"pdf_{i:03d}_{os.path.splitext(pdf_file)[0][:50]}\"\n",
    "        collection_name = \"\".join(c for c in collection_name if c.isalnum() or c in ['_', '-'])\n",
    "        \n",
    "        # Create database directory for this PDF\n",
    "        db_path = f\"./chroma_db/chroma_{os.path.splitext(pdf_file)[0]}\"\n",
    "        os.makedirs(db_path, exist_ok=True)\n",
    "        \n",
    "        # Create a vector store with explicit collection name\n",
    "        vectordb = Chroma.from_documents(\n",
    "            documents=chunks,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=db_path,\n",
    "            collection_name=collection_name\n",
    "        )\n",
    "        \n",
    "        # Persist the vector store\n",
    "        vectordb.persist()\n",
    "        print(f\"Created vector store with {len(chunks)} chunks\")\n",
    "        \n",
    "        # Clean up to free memory\n",
    "        del vectordb\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"All PDF files processed and embedded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0fb2c4",
   "metadata": {},
   "source": [
    "For HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a713818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/10: VISIE _ CONTACT.html...\n",
      "  Loaded 1 pages\n",
      "  Created 2 chunks\n",
      "Created vector store with 2 chunks\n",
      "Processing 2/10: VISIE _ DOCUMIND.html...\n",
      "  Loaded 1 pages\n",
      "  Created 6 chunks\n",
      "Created vector store with 6 chunks\n",
      "Processing 3/10: VISIE _ AI-INSIGHTS.html...\n",
      "  Loaded 1 pages\n",
      "  Created 6 chunks\n",
      "Created vector store with 6 chunks\n",
      "Processing 4/10: VISIE _ KOTHOK.html...\n",
      "  Loaded 1 pages\n",
      "  Created 6 chunks\n",
      "Created vector store with 6 chunks\n",
      "Processing 5/10: VISIE Ltd _ AI Solutions for Innovation.html...\n",
      "  Loaded 1 pages\n",
      "  Created 11 chunks\n",
      "Created vector store with 11 chunks\n",
      "Processing 6/10: VISIE Ltd _ AI Solutions for Innovation_.html...\n",
      "  Loaded 1 pages\n",
      "  Created 2 chunks\n",
      "Error processing Ferdous Bin Ali.pdf: Validation error: name: Expected a name containing 3-512 characters from [a-zA-Z0-9._-], starting and ending with a character in [a-zA-Z0-9]. Got: html_006_VISIELtd_AISolutionsforInnovation_\n",
      "Processing 7/10: VISIE _ ABOUT.html...\n",
      "  Loaded 1 pages\n",
      "  Created 5 chunks\n",
      "Created vector store with 5 chunks\n",
      "Processing 8/10: VISIE _ PAPERS.html...\n",
      "  Loaded 1 pages\n",
      "  Created 7 chunks\n",
      "Created vector store with 7 chunks\n",
      "Processing 9/10: VISIE _ PERCEPT.html...\n",
      "  Loaded 1 pages\n",
      "  Created 7 chunks\n",
      "Created vector store with 7 chunks\n",
      "Processing 10/10: VISIE _ VERIFYID.html...\n",
      "  Loaded 1 pages\n",
      "  Created 6 chunks\n",
      "Created vector store with 6 chunks\n",
      "All HTML files processed and embedded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your HTML files\n",
    "dataset_dir = \"../Data/html_data/\"\n",
    "html_files = [f for f in os.listdir(dataset_dir) if f.endswith('.html')]\n",
    "\n",
    "# Process each HTML file\n",
    "for i, html_file in enumerate(html_files, 1):\n",
    "    try:\n",
    "        file_path = os.path.join(dataset_dir, html_file)\n",
    "        print(f\"Processing {i}/{len(html_files)}: {html_file}...\")\n",
    "\n",
    "        # Load the HTML file\n",
    "        loader = UnstructuredHTMLLoader(file_path=file_path)\n",
    "        documents = loader.load()\n",
    "        print(f\"  Loaded {len(documents)} pages\")\n",
    "        \n",
    "        # Split the documents into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=100\n",
    "        )\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        print(f\"  Created {len(chunks)} chunks\")\n",
    "        \n",
    "        # Create a unique collection name (ChromaDB collection names must be valid)\n",
    "        collection_name = f\"html_{i:03d}_{os.path.splitext(html_file)[0][:50]}\"\n",
    "        collection_name = \"\".join(c for c in collection_name if c.isalnum() or c in ['_', '-'])\n",
    "\n",
    "        # Create database directory for this HTML\n",
    "        db_path = f\"./chroma_db/chroma_{os.path.splitext(html_file)[0]}\"\n",
    "        os.makedirs(db_path, exist_ok=True)\n",
    "        \n",
    "        # Create a vector store with explicit collection name\n",
    "        vectordb = Chroma.from_documents(\n",
    "            documents=chunks,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=db_path,\n",
    "            collection_name=collection_name\n",
    "        )\n",
    "        \n",
    "        # Persist the vector store\n",
    "        vectordb.persist()\n",
    "        print(f\"Created vector store with {len(chunks)} chunks\")\n",
    "        \n",
    "        # Clean up to free memory\n",
    "        del vectordb\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"All HTML files processed and embedded successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
